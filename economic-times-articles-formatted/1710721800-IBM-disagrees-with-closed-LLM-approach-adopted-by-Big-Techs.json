{"url":"https://economictimes.indiatimes.com/tech/information-tech/ibm-disagrees-with-closed-llm-approach-adopted-by-big-techs/articleshow/108568648.cms","title":"IBM disagrees with closed LLM approach adopted by Big Techs","description":"IBM's chief privacy and trust officer Christina Montgomery said the way to develop AI models is to be inclusive and transparent about the datasets used to train LLMs.","content":"IBM does not agree with a closed large-language model approach several global companies such as Open AI, Microsoft, Google, and others have adopted, the company’s chief privacy and trust officer Christina Montgomery said.The best way to develop artificial intelligence (AI)-based models was to be inclusive and transparent about the datasets used to train such LLMs, she told ET.“If you look at models, like ChatGPT, it is a very closed model. You do not see the inputs and they do not disclose a lot about the data that is being used to train. From an IBM perspective, we think that is wrong. The future is an open one, not a closed set of licensing machines,” Montgomery said.Apart from holding the foundational AI models responsible for the training, companies and persons deploying these models should also be accountable and responsible for the response they generate.Generative AI models, for example, should give their enterprise customers more information about the data that went into training their model which enables or empowers the end customer to be assured that there is no bias. Such disclosures, especially around data sets used for training and the labels on those data sets can also be handed over to the regulator as proof in high-risk use cases, she said.","cleaned_content":"ibm does not agree with a closed large language model approach several global companies such as open ai microsoft google and others have adopted the company s chief privacy and trust officer christina montgomery said the best way to develop artificial intelligence ai based models was to be inclusive and transparent about the datasets used to train such llms she told et if you look at models like chatgpt it is a very closed model you do not see the inputs and they do not disclose a lot about the data that is being used to train from an ibm perspective we think that is wrong the future is an open one not a closed set of licensing machines montgomery said apart from holding the foundational ai models responsible for the training companies and persons deploying these models should also be accountable and responsible for the response they generate generative ai models for example should give their enterprise customers more information about the data that went into training their model which enables or empowers the end customer to be assured that there is no bias such disclosures especially around data sets used for training and the labels on those data sets can also be handed over to the regulator as proof in high risk use cases she said","timestamp":"2024-03-18T06:00:00+05:30","market_timestamp":"2024-03-18T09:15:00+05:30","off_market_hours":true}